{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wEE8kKfzCBRx",
        "outputId": "b9632442-dce2-4a74-d3a3-adcf5d05a340"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: annoy in /usr/local/lib/python3.10/dist-packages (1.17.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "!pip install annoy\n",
        "import re\n",
        "\n",
        "from annoy import AnnoyIndex\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "def crawl_markdown_files(root_dir):\n",
        "    \"\"\"\n",
        "    Crawls through directory and extracts text from markdown files.\n",
        "    Returns a dict with filepath as key and content as value.\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    for path in Path(root_dir).rglob('*.md'):\n",
        "        try:\n",
        "            with open(path, 'r', encoding='utf-8') as f:\n",
        "                results[str(path)] = f.read()\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {path}: {e}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "crawled_result = crawl_markdown_files('workvault')\n",
        "list_crawled_result_values = list(crawled_result.values())\n",
        "\n",
        "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "model = SentenceTransformer(\"msmarco-distilbert-dot-v5\")\n",
        "f = 768  # Length of item vector that will be indexed\n",
        "\n",
        "crawled_result_embeddings = model.encode(\n",
        "    list_crawled_result_values,\n",
        "    convert_to_tensor=True\n",
        ")\n",
        "crawled_result_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl7QQ5aStK8j",
        "outputId": "3752d82c-7dac-4066-abce-612ae459c90b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "actively working on debugging the PnL T-1... I don't know what the issue is. it seems to be a BXII thing\n",
            "- in custom_valuation_runner.py, in \n",
            "\n",
            "![[Pasted image 20241022164921.png]]\n",
            "this thing is empty\n",
            "![[Pasted image 20241022165327.png]]\n",
            "\n",
            "maybe here\n",
            "![[Pasted image 20241022170141.png]]\n",
            "\n",
            "\n",
            "0.7509298324584961\n",
            "@@@@@@\n",
            "\n",
            "- rebase onto new dev\n",
            "- fix merge conflicts\n",
            "\n",
            "0.7405896782875061\n",
            "@@@@@@\n",
            "\n",
            "- gitlab package registries\n",
            "- untracked launch.json from batch scripts\n",
            "- consolidated recluse reports logging\n",
            "- \n",
            "\n",
            "0.7185502052307129\n",
            "@@@@@@\n",
            "\n",
            "- [x] i just made you both admins\n",
            "- [ ] how to refresh\n",
            "- [ ] the excel file\n",
            "\t- [ ] someone will have to make this for 2025\n",
            "\n",
            "0.7134351134300232\n",
            "@@@@@@\n",
            "\n",
            "- can we merge into dev?\n",
            "\t- need to pip install `filter-engine`\n",
            "- need to rebase the `current implementation` branch onto dev\n",
            "\n",
            "0.7090854048728943\n",
            "@@@@@@\n",
            "\n",
            "- format some files you didn't actually touch (and only those!! Don't format your actual code files at least, in the same merge request that's getting reviewed)\n",
            "\t- format on a dev branch before it goes into prod - you know the merge is already in and going to go\n",
            "\t- tacking things on after a merge request into dev if you know it's gonna go right in and not confuse people\n",
            "- reorder the imports as suggested by pylint\n",
            "\t- using isort\n",
            "\n",
            "0.706859290599823\n",
            "@@@@@@\n",
            "\n",
            "- what all branches do I have in recluse reports right now?\n",
            "- Which ones can I get rid of?\n",
            "- I know the index fee logic one is behind\n",
            "\n",
            "0.7029814720153809\n",
            "@@@@@@\n",
            "\n",
            "Ellen married\n",
            "\n",
            "Zach race\n",
            "\n",
            "\n",
            "0.7007956504821777\n",
            "@@@@@@\n",
            "\n",
            "- devops\n",
            "\t- need to check with them if they want me?\n",
            "\t- is there work to do on that team?\n",
            "\n",
            "0.70035719871521\n",
            "@@@@@@\n",
            "\n",
            "==refactoring by going through the code line-by-line.  finished on `_generate_index_returns`==\n",
            "\n",
            "0.6972719430923462\n",
            "@@@@@@\n",
            "\n"
          ]
        }
      ],
      "source": [
        "new_query_text = \"we're going to rerun pnl\"\n",
        "new_query_embedding = model.encode(new_query_text, convert_to_tensor=True)\n",
        "\n",
        "queries = [\n",
        "    new_query_text\n",
        "]\n",
        "\n",
        "query_embedding = model.encode(queries, convert_to_tensor=True)\n",
        "\n",
        "semantic_search_result = util.semantic_search(\n",
        "    query_embedding,\n",
        "    crawled_result_embeddings,\n",
        ")\n",
        "semantic_search_result[0]\n",
        "\n",
        "\n",
        "for my_dict in semantic_search_result[0]:\n",
        "  text = list_crawled_result_values[my_dict['corpus_id']]\n",
        "  print(text)\n",
        "  print('')\n",
        "  print(my_dict['score'])\n",
        "  print('@@@@@@')\n",
        "  print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPBmeyfxwwiE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
